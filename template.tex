%%% Copyright (c) 2010, Илья w-495 Никитин%%%%%% Разрешается повторное распространение и использование как в виде исходного%%% кода, так и в двоичной форме, если таковая будет получена, %%% с изменениями или без, при соблюдении следующих условий:%%%%%%     * При повторном распространении исходного кода должно оставаться%%%       указанное выше уведомление об авторском праве, этот список условий и%%%       последующий отказ от гарантий.%%%     * Ни имя w-495, ни имена друзей или консультантов не могут быть%%%       использованы в качестве поддержки или продвижения продуктов,%%%       основанных на этом коде без предварительного письменного разрешения. %%%%%% Этот код предоставлен владельцом авторских прав и/или другими%%% сторонами "как она есть" без какого-либо вида гарантий, выраженных явно%%% или подразумеваемых, включая, но не ограничиваясь ими, подразумеваемые%%% гарантии коммерческой ценности и пригодности для конкретной цели. Ни в%%% коем случае, если не требуется соответствующим законом, или не установлено%%% в устной форме, ни один владелец авторских прав и ни одно  другое лицо,%%% которое может изменять и/или повторно распространять программу, как было%%% сказано выше, не несёт ответственности, включая любые общие, случайные,%%% специальные или последовавшие убытки, вследствие использования или%%% невозможности использования программы (включая, но не ограничиваясь%%% потерей данных, или данными, ставшими неправильными, или потерями%%% принесенными из-за вас или третьих лиц, или отказом программы работать%%% совместно с другими программами), даже если такой владелец или другое%%% лицо были извещены о возможности таких убытков.\documentclass[unicode, 12pt, a4paper,oneside]{article}	%% Варианты []:		% fleqn --- сдвигает формулы влево	%% Варианты {}:		% book		% report		% article		% letter		% minimal (???)\usepackage{styles/main} 	% подключаем набор стилей \usepackage{booktabs}\usepackage{adjustbox}\ifpdf	\hypersetup{ 			pdffitwindow=false,			pdfstartview={FitH},					pdftitle={Курсовая работа}, 		pdfauthor={Ларионов Даниил}, 		pdfcreator={pdfLaTeX + MakeIndex + BibTeX}, 		pdfsubject={Машинное обучение в задачах анализа текстов на естественном языке}, 		pdfproducer={Ларионов Даниил}, 		pdfkeywords={Курсовая}	}\fi\begin{document}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% бесполезное содержимое%%%	\input{src/work-titlepage} 	% титульный лист	\tableofcontents 		% оглавление	\pagebreak		\input{\SRC/introduction} 		%% постановка	\input{\SRC/related-work}	\input{\SRC/methodology} 	%% теоретическая часть	\input{\SRC/experiments} 		%% решение			%% примеры	\input{\SRC/results} 	%% выводы		\begin{thebibliography}{9}		\bibitem{muronets} Olga V. Muronets, Content of Social Networks: Trends and Patterns.		\bibitem{twitter-source} Miles Osborne and Mark Dredze. 2014. Facebook, Twitter and Google Plus for Breaking News: Is There a Winner?. In ICWSM		\bibitem{event-detection-survey} Atefeh F., and Khreich W. (2015), A Survey of Techniques for Event Detection in Twitter, Computational Intelligence, 31, 132–164, doi: 10.1111/coin.12017		\bibitem{identifying-disasters} Alfredo Cobo, Denis Parra, Jaime Navón: Identifying Relevant Messages in a Twitter-based Citizen Channel for Natural Disaster Situations. CoRR abs/1503.05784 (2015)		\bibitem{cnn-crisis} Tien Nguyen, Dat \& Ali Al Mannai, Kamela \& Joty, Shafiq \& Sajjad, Hassan \& Imran, Muhammad \& Mitra, Prasenjit. (2016). Rapid Classification of Crisis-Related Data on Social Networks using Convolutional Neural Networks.		\bibitem{stanford-nlp} Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pp. 363-370. http://nlp.stanford.edu/~manning/papers/gibbscrf3.pdf		\bibitem{qt2s}Emadi, Noora Al et al. “QT2S: A System for Monitoring Road Traffic Via Fine Grounding of Tweets.” ICWSM (2017).		\bibitem{arctic}Devyatkin D., Shelmanov A. (2017) Text Processing Framework for Emergency Event Detection in the Arctic Zone. In: Kalinichenko L., Kuznetsov S., Manolopoulos Y. (eds) Data Analytics and Management in Data Intensive Domains. DAMDID/RCDL 2016. Communications in Computer and Information Science, vol 706. Springer, Cham		\bibitem{matching}To, Hien \& Agrawal, Sumeet \& Ho Kim, Seon \& Shahabi, Cyrus. (2017). On Identifying Disaster-Related Tweets: Matching-Based or Learning-Based?. 10.1109/BigMM.2017.82.		\bibitem{crisislex} Olteanu, A., Castillo, C., Diaz, F., \& Vieweg, S. (2014). . In International AAAI Conference on Web and Social Media. Retrieved from https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/view/8091		\bibitem{spacy} spaCy - Industrial-Strength Natural Language Processing; \url{https://spacy.io/}		\bibitem{gensim} Software Framework for Topic Modelling with Large Corpora. Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka. Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks.		\bibitem{w2v} Distributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, GS Corrado, J Dean. Advances in neural information processing systems, 3111-3119		\bibitem{infersent} A. Conneau, D. Kiela, H. Schwenk, L. Barrault, A. Bordes, Supervised Learning of Universal Sentence Representations from Natural Language Inference Data. arXiv preprint arXiv:1705.02364.		\bibitem{word2vec} T. Mikolov, K. Chen, G. Corrado, J. Dean, Efficient Estimation of Word Representations in Vector Space		\bibitem{nltk} Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.		\bibitem{randomforest} L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.		\bibitem{liblinear} R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A library for large linear classification Journal of Machine Learning Research 9(2008), 1871-1874.		\bibitem{lightgbm} Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. "LightGBM: A Highly Efficient Gradient Boosting Decision Tree". In Advances in Neural Information Processing Systems (NIPS), pp. 3149-3157. 2017.		\bibitem{relu} Vinod Nair and Geoffrey Hinton. Rectified Linear Units Improve Restricted Boltzmann Machines. ICML. 2010		\bibitem{cnn} Yoon Kim. Convolutional Neural Networks for Sentence Classification. http://arxiv.org/abs/1408.5882		\bibitem{pytorch} Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam. Automatic differentiation in PyTorch. NIPS-W. 2017		\bibitem{fasttext} P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information. Transactions of the Association for Computational Linguistics. 2017. Vol. 5. pp 135-146.		\bibitem{glove} Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. GloVe: Global Vectors for Word Representation. 2015.		\bibitem{dsieve} Roy Chowdhury S, Purohit H, Imran M. D-sieve: a novel data processing engine for efficient handling of crises-related social messages. InProceedings of the 24th International Conference on World Wide Web 2015 May 18 (pp. 1227-1232). ACM.		\bibitem{semi} Zhang S, Vucetic S. Semi-supervised discovery of informative tweets during the emerging disasters. arXiv preprint arXiv:1610.03750. 2016 Oct 12.		\bibitem{domain} Li H, Caragea D, Caragea C, Herndon N. Disaster response aided by tweet classification with a domain adaptation approach. Journal of Contingencies and Crisis Management. 2018 Mar;26(1):16-27.		\bibitem{clstm} Zhou C, Sun C, Liu Z, Lau F. A C-LSTM neural network for text classification. arXiv preprint arXiv:1511.08630. 2015 Nov 27.	\end{thebibliography}		\end{document}%%%%%%