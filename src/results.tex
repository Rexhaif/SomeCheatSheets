%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% теоретическая часть, обоснование и формулы
%%%

\section{Результаты и обсуждение}
Результаты измерений представлены в таблицах 1-2. Ниже мы обсудим некоторые идеи, на которые мы натолкнулись в процессе экспериментов.
\begin{itemize}
\item В большинстве случаев, эмбеддинги натренированные на корпусе общей тематики показали себя лучше, чем натренированные на корпусе твитов. Нам кажется, это связано с тем, что лексикон, используемы при описании кризисных ситуаций отличается от твиттер-специфичного и более близок к общему. Так-же на результаты могло повлиять различие в размерах корпусов, на которых тренировались эмбеддинги.
\item Эмбеддинги предложений лучше предсказывают смысл текста чем средний вектор эмбеддингов слов. Мы считаем это обоснованным, т.к взятие среднего сильно замазывает истинную картину смысла предложения. Более того, среднее не учитывает важность одних слов в одном части текста и неважность других. Однако высокая размерность выходного вектора эмбеддингов предложения делает невозмодным использование их в паре с некоторыми алгоритмами классификации.
\item Нейросетевые классификаторы почти всегда обеспечивают более стабильное качество предсказаний в отличии от классических моделей(кроме lightgbm). Следовательно, мы будем получать стабильно хорошие результаты независимо от данных для тренировки и для теста.
\end{itemize}

\section{Заключение}
В ходе данной работы мв провели качественное сравнение различных пар эмбеддинг-классификатор и по результатам измерений, лучшей парой является Fasttext, натренированный на CrisisLexT6 и CNN for text classification. Стоит так же заметить, что полученные результаты на 2\% превосходят по Acccuracy результаты измерения в одной из недавних статей по данному датасету \cite{domain}

\begin{table}[]
\centering
\caption{Accuracy}
\label{acc1}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{@{}llllllllllllll@{}}
\multicolumn{1}{l|}{}                         & \multicolumn{1}{l|}{FstMean} & \multicolumn{1}{l|}{FstStd} & \multicolumn{1}{l|}{FsWikiMean} & \multicolumn{1}{l|}{FsWikiStd} & \multicolumn{1}{l|}{GlCCMean} & \multicolumn{1}{l|}{GlCCStd} & \multicolumn{1}{l|}{GlTwtMean} & \multicolumn{1}{l|}{GlTwtStd} & \multicolumn{1}{l|}{W2VMean} & \multicolumn{1}{l|}{W2VStd} & \multicolumn{1}{l|}{InfStMean} & \multicolumn{1}{l|}{InfStStd} & \multicolumn{1}{l|}{Baseline} \\ \midrule
\multicolumn{1}{|l|}{LogReg}         & 0.8772                    & 0.0690                   & 0.8270                    & 0.0757                   & 0.8846                    & 0.0476                   & 0.8486                    & 0.0613                   & 0.8897                    & 0.0573                   & 0.8930                    & 0.0439                   & 0.5434                        \\ \cmidrule(r){1-1}
\multicolumn{1}{|l|}{Random Forest}   & 0.8733                    & 0.0747                   & 0.8298                    & 0.0853                   & 0.8762                    & 0.0627                   & 0.8452                    & 0.0825                   & 0.8776                    & 0.0720                   & 0.8975                    & 0.0425                   & 0.5434                        \\ \cmidrule(r){1-1}
\multicolumn{1}{|l|}{GBDT}       & 0.9113                    & 0.0009                   & 0.8912                    & 0.0020                   & 0.9256                    & 0.0018                   & 0.8912                    & 0.0020                   & 0.9145                    & 0.0027                   & N/A                       &N/A                          & 0.5434                        \\ \cmidrule(r){1-1}
\multicolumn{1}{|l|}{FullyConnected} & 0.9027                    & 0.0036                   & 0.8599                    & 0.0041                   & 0.9162                    & 0.0039                   & 0.8718                    & 0.0029                   & 0.9058                    & 0.0020                   & 0.9092                    & 0.0026                   & 0.5434                        \\
\cmidrule(r){1-1}
\multicolumn{1}{|l|}{CNN} & {\bf 0.9392} &0.0033 &0.9296 &0.0034 & 0.9346 &0.0027 & 0.9230 &0.0014 & 0.9248 &0.0019 &N/A &N/A & 0.5434 \\
\cmidrule(r){1-1}
\multicolumn{1}{|l|}{CLSTM} & 0.9153 & 0.0025 & 0.9159 & 0.0052 & 0.9170 & 0.0050 & 0.9088 & 0.0072 &0.9191&0.0051&N/A&N/A&0.5434\\
 \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}


\begin{table}[]
\centering
\caption{F1}
\label{f11}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{@{}|l|lllllllllllll@{}}
\multicolumn{1}{l|}{}                      & \multicolumn{1}{l|}{Fst Mean} & \multicolumn{1}{l|}{Fst Std} & \multicolumn{1}{l|}{FstWiki Mean} & \multicolumn{1}{l|}{FstWiki Std} & \multicolumn{1}{l|}{GlCC Mean} & \multicolumn{1}{l|}{GlCC Std} & \multicolumn{1}{l|}{GlTwt Mean} & \multicolumn{1}{l|}{GlTwt Std} & \multicolumn{1}{l|}{W2V Mean} & \multicolumn{1}{l|}{W2V Std} & \multicolumn{1}{l|}{InfSt Mean} & \multicolumn{1}{l|}{InfSt Std} & \multicolumn{1}{l|}{Baseline} \\ \midrule
LogReg        & 0.8743                        & 0.0848                       & 0.8256                            & 0.0921                           & 0.8861                         & 0.0528                        & 0.8514                          & 0.0693                         & 0.8899                        & 0.0671                       & 0.8945                          & 0.0493                         & 0.7041                        \\ \cmidrule(r){1-1}
Random Forest   & 0.8693                        & 0.0952                       & 0.8233                            & 0.1119                           & 0.8744                         & 0.0741                        & 0.8399                          & 0.1052                         & 0.8744                        & 0.0887                       & 0.8945                          & 0.0493                         & 0.7041                        \\ \cmidrule(r){1-1}
GBDT       & 0.9171                        & 0.0009                       & 0.8984                            & 0.0014                           & 0.9306                         & 0.0013                        & 0.8986                          & 0.0023                         & 0.9201                        & 0.0026                       & N/A                             & N/A                            & 0.7041                        \\ \cmidrule(r){1-1}
FullyConnected & 0.9099                        & 0.0037                       & 0.8684                            & 0.0039                           & 0.9223                         & 0.0037                        & 0.8808                          & 0.0028                         & 0.9120                        & 0.0021                       & 0.9088                          & 0.0021                         & 0.7041                        \\ 
\cmidrule(r){1-1}
CNN & {\bf 0.9432} &0.0034 &0.9343 &0.0035 & 0.9389 &0.0029 & 0.9272 &0.0017 & 0.9296 &0.0017 &N/A &N/A & 0.7041 \\
\cmidrule(r){1-1}
CLSTM & 0.9211 & 0.0022 & 0.9222 & 0.0036& 0.9226&0.0061& 0.9153& 0.0049&0.9230&0.0055&N/A&N/A& 0.7041 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

