%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% задание
%%%

\section{Эксперименты}
\subsection{Датасет}
Для наших замеров мы выбрали датасет CrisisLexT6. Он содержит 60000 твитов, так или иначе связанных с 6 различными крупными ЧС. Каждый твите промаркирован по тому, относится он к ЧС или нет. Кроме того, несколько твитов присутствуют без класса. Мы удалили их из датасета. Набор данных хорошо сбалансирован, потому дополнительных мер для достижения баланса классов не требуется. Для K-fold кросс валидации мы используем 5 как значение праметра K, следовательно, каждый из блоков будет содержать 12000 объектов.

\subsection{Препроцессинг}
Мы используем регулярные выражения для того чтобы очистить текст и объединить разрозненные хэштеги, ссылки и эмоджи. Для начала, текст каждого твита разбивается на токены с помощью NLTK TweetTokenizer. После мы используем пакет "re" из стандартной библиотеки Python для применения регулярных выражений.

\subsection{Классификаторы}
В наборе тестируемых алгоритмов классификации представлены как классические модели, так и нейросетевые классификаторы:
\begin{itemize}
	\item Logistic Regression, предложенная разработчитками Liblinear \cite{liblinear} с интерфейсом в Scikit-learn.
	\item Random Forest, описанный в \cite{randomforest}, реализованный в Scikit-learn.
	\item Gradient Boosted Decision Trees, реализованные в LightGBM \cite{lightgbm}.
	\item Fully-connected neural nework
	\item CNN for text classification, описанные в \cite{cnn}.
	\item C-LSTM, предложенные в \cite{clstm}.
\end{itemize}

\subsubsection{Архитектуры Нейросетевых классификаторов}
{\bf Полносвязанная нейронная сеть} представляет собой простой двуслойный перцептрон с дропаут слоем посередине. Функции активации для первого и второго слоя - ReLU и Softmax соответственно. Сеть реализованна на фреймворке PyTorch 0.4.\\
{\bf Сверточная нейронная сеть для классификации текстов}, предложенная Юном Кимом используется для классификации документов, где каждое словов представлено соотв. вектором. Первым слоем идут несколько несвязанных сверток с различными размерами фильтров. Полученные feature maps проходят через ReLU активация и склеиваются в один вектор. После, вектор проходит через полносвязный слой с Softmax активацией и на выходе мы получаем вероятности принадлежности к каждому из двух классов. \\
{\bf C-LSTM} построена таким образом, чтобы извлечь последовательные контекстные признаке с помощью сверточного слоя и после найти долгосрочные зависимости с помощью LSTM слоя. После, ветора признаков проходят через два полносвязаных слоя с Tahn и Softmax активацией.

\subsubsection{Гиперпараметры}
Там, где не указано, мы использовали гиперпараметры, идущие по умолчанию для данного алгоритма.
\begin{itemize}
		\item {\bf Random Forest} Количество деревьев в лесу - 1000.
		\item {\bf Gradient Boosted Decision Trees} Максимальная глубина дерева - 20, число ветвей - 11, learning rate - 0.05.  Количество деревьев - 4000 с ранней остановкой через 200 итераций.
		\item {\bf Fully-Connected Network} Размер скрытого слоя - 256, вероятность дропаута -  0.5. Тренировка проводилась в течении 10 эпох с ранней остановкой через три эпохи. Оптимизатор - Adam, функция ошибки -  BinaryCrossEntropy.
		\item For {\bf CNN for sentence classification} Размеры фильтров [3, 4, 5] с 512 выходными каналами на каждый. Дропаут 0.5. Настройки тренировки идентичны полносвязной сети.
		\item {\bf C-LSTM} Размер свертки - 3 с 128 каналами, max pooling с ядром размера 2, LSTM hidden size - 80 и дропаут 0.1. Размер первого полносвязного слоя - 60. Настройки тренировки идентичны полносвязной сети.
\end{itemize}

\subsection{Эмбеддинги}
В тестируемом наборе эмбеддингов пристуствуют FastText \cite{fasttext}, в варианте, натренированном на нашем датасете и на корпусе английской википедии; GloVe\cite{glove}, натренированный на корпусе CommonCrawl и на корпусе твитов; Word2Vec\cite{word2vec}, натренированный на нашем датасете. В качестве эмбеддингов предложений используется InferSent\cite{infersent}, натренированный на корпусе AllNLI.

\subsection{Метрики качества и оборудование}
Так как используемый датасет хорошо сбалансирован по классам, мы решили использовать Accuracy и F1-меру как метрики качества. Так же, нам кажется необходимым привести замеры для baseline, в которм всем элементам тестовой выборки проставлен класс 1, для сравнения с результатами.\\
Все эксперименты проведены на машине с GPU Nvidia Tesla K20, 64Gb оперативной памяти и 32 ядрами CPU.




