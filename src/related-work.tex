%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% выводы
%%%

\section{Обзор литературы}
В целом, сама идея того, что социальные медиа можно использовать как канал оперативной информации о происходящих черезвычайных ситуациях, уже давно интересует исследователей. Обьективная полезность такого канала была показана в \cite{twitter-source}. В данной работе был проведен анализ нескольких крупных социальных медиа на предмет того, как полно данные описываются их пользователями и того, как оперативно эти описания появляются. В результате проведенных исследований было выяснено, что хоть и все анализируемые социальные медиа имели достаточно полное описание целевых событий, платформа Twitter охарактеризовала себя как наиболее оперативный источик информации. Поэтому, в нашей работе мы сфокусируемся на анализе Twitter-специфичных данных.\\

Хоть и задача анализа текста из твитов является, в общем, задачей анализа текста на естественном языке, мы должны учитывать "специфичность" того языка, на котором пользователи Twitter пишут сообщения(обилие сокращений, хэштегов, грамматических ошибок и т.д). Анализ способов применения различных алгоритмов машинного обучения для задачи классификации twitter-специфичного текста были представлены в работах \cite{event-detection-survey, identifying-disasters}. В этих исследованиях авторы анализирует различные техники, применяемые для задачи обнаружения событий. Список анализируемых техник включает в себя как и алгоритмы машинного обучения, так и статистический анализ. В первой работе авторы не проводят какие либо результаты экспериментов, но обозревают работы дргих исследователей по части используемых алгоритмов и наборов признаков. Во второй работе исследователи проводят эксперименты на пяти различных алгоритмах классификации и приводят метрики, полученные в результате. В заключении авторы называют два наиболее эффективных алгоритма: SVM и Random Forest. Однако те показатели, которые были получены на этих алгоритмах выглядят недостаточными для приемлемого функционирования анализа для наших задач. Мы намерены протестировать некоторые современные state-of-the-art модели на основен нейронных сетей(пример применения такой модели был показан в работе \cite{cnn-crisis}) что бы получить исчерпывающий ответ на вопрос: какой алгоритм классификации текстов показывает лучшие результаты на twitter-специфичных данных.\\

Ещё одним интересным подходом к классификации текстов является pattern-based matching. Как показано в работе \cite{matching}, алгоритм на основе сопоставления с образцовым набором фраз и слов может давать неплохие показатели точности и полноты, однако он не лишен и сивоих недостатков. В следствии того, что в нашей задачи нам гораздо важнее получить информацию из твитов, непосредственно связанных с происходящим событием, а не общим упоминанием подобного события, нам важно учитывать внутреннюю структуру текста. Pattern-based matching, по мнению исследователей в этой работе, способен верно угадывать общий смысл исходя из того, какие слова используются в сообщении, однако он полностью игнорирует связь между словами. Авторы оригинальной статьи показывают, что алгоритм на основе машинного обучения выигрывают у него по показателю релевантности классифицируемых сообщения событию.\\

Рассмотрим существующие датасеты, подходящие для нашей задачи. Во-первых, нельзя не упомянуть семейство датасетов CrisisLexT6 \cite{crisislex}. На сегодня это самая объемная коллекция твитов, связанных с тем или иным черезвычайным проишествием. Для нашей задачи видится интересным датасет CrisisLexT6. Он содержит yнесколько десятков тысяч твитов, которые в той или иной мере были связаны с громкими проишествиями в США и мире за период 2011-2013 годов. Каждый из твитов имеют метку о уровне связанности с основным проишествием. Однако, так как своей задачей мы ставим обнаружение не только громких и массовых черезвычайных ситуаций, но и меньшего размера, локальных, нам так же потребуется датасет для такого типа проишествий. Здесь наиболее интересным мы считаем датасет CloudFlower10k. Он содержит 10 тысяч твитов о ЧС различного масштаба: от лесных пожаров до небольших ДТП. Данные отобраны вручную и каждый твит идет вкупе с коэффициентом уверенности в том, что твит не является спамом и вообще содержит достоверную информацию о проишествии. 

\pagebreak
